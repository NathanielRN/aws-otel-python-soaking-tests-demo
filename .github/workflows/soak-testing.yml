name: Soak Testing
on:
  # schedule:
  #   - cron: '0 10 * * *' # every day at 10 am UTC: pst 2am
  push:
    branches: [ main ]
env:
  # Language Specific
  PROCESS_COMMAND_LINE: /usr/local/bin/python3 application.py
  PROCESS_EXECUTABLE_NAME: python3
  # Global Env Vars
  AWS_REGION: us-west-2

jobs:
  test_apps_and_publish_results:
    name: Publish App and Soak Test and Publish Results
    runs-on: ubuntu-latest
    permissions:
      contents: write
      packages: write
    strategy:
      fail-fast: true
      matrix:
        app-platform: [ flask ]
        # instrumentation-type: [ auto, manual ]
        instrumentation-type: [ auto ]
    env:
      APP_PATH: integration-test-apps/${{ matrix.instrumentation-type}}-instrumentation/${{ matrix.app-platform }}
      HOURS_TO_RUN: 5
      ASSUMED_NUM_OF_CPUS: 2
      IMAGE_SUFFIX: sample-app-${{ matrix.app-platform }}-${{ matrix.instrumentation-type }}-${{ github.sha }}
    steps:
      - uses: actions/checkout@v2
      # # Only for manual app
      # - uses: actions/checkout@v2
      #   if: ${{ matrix.instrumentation-type }} == manual
      #   with:
      #     repository: open-telemetry/opentelemetry-python
      #     path: ${{ env.APP_PATH }}/opentelemetry-python-core
      # - uses: actions/checkout@v2
      #   if: ${{ matrix.instrumentation-type }} == manual
      #   with:
      #     repository: open-telemetry/opentelemetry-python-contrib
      #     path: ${{ env.APP_PATH }}/opentelemetry-python-contrib
      # - name: Log in to the GitHub Container Registry
      #   uses: docker/login-action@v1
      #   with:
      #     registry: ghcr.io
      #     username: ${{ github.actor }}
      #     password: ${{ secrets.GITHUB_TOKEN }}
      # - name: Set up Docker Buildx
      #   uses: docker/setup-buildx-action@v1
      # - name: Cache Docker layers
      #   uses: actions/cache@v2
      #   with:
      #     path: /tmp/.buildx-cache
      #     key: ${{ runner.os }}-buildx-${{ github.sha }}
      #     restore-keys: |
      #       ${{ runner.os }}-buildx-
      # - name: Extract metadata (tags, labels) for Docker
      #   id: docker-image-metadata
      #   uses: docker/metadata-action@98669ae865ea3cffbcbaa878cf57c20bbf1c6c38
      #   with:
      #     images: ghcr.io/${{ github.repository }}-${{ env.IMAGE_SUFFIX }}
      # - name: Build and Push Docker image
      #   uses: docker/build-push-action@v2
      #   with:
      #     push: true
      #     context: ${{ env.APP_PATH }}
      #     tags: ${{ steps.docker-image-metadata.outputs.tags }}
      #     labels: ${{ steps.docker-image-metadata.outputs.labels }}
      #     cache-from: type=local,src=/tmp/.buildx-cache
      #     cache-to: type=local,dest=/tmp/.buildx-cache
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      # - name: Run Sample App & OTel Collector + Load Generator
      #   working-directory: .github/collector
      #   env:
      #     APP_IMAGE: ${{ steps.docker-image-metadata.outputs.tags }}
      #     INSTANCE_ID: ${{ github.run_id }}-${{ github.run_number }}
      #     LISTEN_ADDRESS: 0.0.0.0:8080
      #     LOG_GROUP_NAME: ${{ github.repository }}/soak-tests
      #     LOGS_NAMESPACE: ${{ github.repository }}/soak-tests
      #     LOG_STREAM_NAME: ${{ env.IMAGE_SUFFIX }}
      #     PROCESS_COMMAND_LINE: ${{ env.PROCESS_COMMAND_LINE }}
      #     PROCESS_EXECUTABLE_NAME: ${{ env.PROCESS_EXECUTABLE_NAME }}
      #     HOSTMETRICS_COLLECTION_INTERVAL: 10m
      #     SOAK_TEST_DURATION: ${{ env.HOURS_TO_RUN }}h
      #   run: docker-compose up --abort-on-container-exit
      # - name: Get a snapshot of metrics
      #   run: >-
      #     mkdir -p soak-tests/snapshots/${{ github.sha }};
      #     for metric_kind in cpu-load memory-usage;
      #     do
      #       aws cloudwatch get-metric-widget-image --metric-widget "$(
      #         cat ./.github/aws-cloudwatch-api-values/get-metric-widget-statistics/$metric_kind-metric-widget.json |
      #         sed -e "s/<HOURS_TO_RUN>/${{ env.HOURS_TO_RUN }}/g" \
      #             -e "s/<ASSUMED_NUM_OF_CPUS>/${{ env.ASSUMED_NUM_OF_CPUS }}/g" \
      #             -e "s/<LOGS_NAMESPACE>/$(echo ${{ github.repository }}/soak-tests | sed 's/\//\\\//g')/g" \
      #             -e "s/<DIMENSION_1_VALUE>/$(echo ${{ env.PROCESS_COMMAND_LINE }} | sed 's/\//\\\//g')/g"
      #       )" |
      #       jq -r '.MetricWidgetImage' |
      #       base64 -d > soak-tests/snapshots/${{ github.sha }}/${{ matrix.app-platform }}-${{ matrix.instrumentation-type }}-$metric_kind-results.png;
      #     done
      # - name: Commmit snapshots to repository
      #   uses: EndBug/add-and-commit@v7
      #   with:
      #     add: soak-tests/snapshots
      #     branch: gh-pages
      #     message: 'Adding Soak Tests Snapshots'
      - name: Prepare Soak Test results as JSON output
        run: >-
          HOURS_TO_RUN_IN_SECONDS=$(expr 60 \* 60 \* ${{ env.HOURS_TO_RUN }});
          COMMON_API_PARAMETERS="
          --namespace ${{ github.repository }}/soak-tests
          --start-time $(date -u -d '${{ env.HOURS_TO_RUN }} hours ago' +%FT%TZ)
          --end-time $(date -u +%FT%TZ)
          --period $HOURS_TO_RUN_IN_SECONDS
          --region ${{ env.AWS_REGION }}
          ";
          OVERALL_CPU_LOAD=$(
            aws cloudwatch get-metric-statistics $(echo $COMMON_API_PARAMETERS) \
                                                 --dimensions Name=process.command_line,Value='${{ env.PROCESS_COMMAND_LINE }}' \
                                                 --metric-name process.cpu.time \
                                                 --statistics Maximum |
            jq -r ".Datapoints[] | .Value=.Maximum/$HOURS_TO_RUN_IN_SECONDS/${{ env.ASSUMED_NUM_OF_CPUS }}*100 | {Name: \"Soak Test Overall CPU Load\", Value, Unit: \"Percent\"}"
          )
          AVERAGE_VIRTUAL_MEMORY=$(
            aws cloudwatch get-metric-statistics $(echo $COMMON_API_PARAMETERS) \
                                                 --dimensions Name=process.command_line,Value='${{ env.PROCESS_COMMAND_LINE }}' \
                                                 --metric-name process.memory.virtual_usage \
                                                 --statistics Average |
            jq -r '.Datapoints[] | {Name: "Soak Test Average Virtual Memory Used", Value: .Average, Unit}'
          );
          jq -n "[$OVERALL_CPU_LOAD] + [$AVERAGE_VIRTUAL_MEMORY] | {benchmarks: .}" |
          tee output.json
      - name: Report on Soak Test Averages results
        uses: NathanielRN/github-action-benchmark@v1.8.2-alpha3
        with:
          name: Soak Test Results - sample-app-${{ matrix.app-platform }}-${{ matrix.instrumentation-type }}
          tool: custombenchmark
          output-file-path: output.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          max-items-in-chart: 100
          alert-threshold: 200%
          # Does not work as expected, see: https://github.com/open-telemetry/opentelemetry-python/pull/1478
          # comment-always: true
          # fail-on-alert: true
          auto-push: ${{ github.ref == 'refs/heads/main' }}
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: soak-tests/per-commit-overall-results
